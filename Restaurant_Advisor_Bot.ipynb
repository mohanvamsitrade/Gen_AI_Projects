{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOt5yfCvQCjK6/+2a1mAJiO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohanvamsitrade/Gen_AI_Projects/blob/main/Restaurant_Advisor_Bot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ZJLfrV8m4DWU"
      },
      "outputs": [],
      "source": [
        "from secret_key import huggingface_key1\n",
        "\n",
        "import os\n",
        "\n",
        "os.environ['HUGGINGFACEHUB_API_TOKEN'] = huggingface_key1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain"
      ],
      "metadata": {
        "id": "IzVJZHuU4lh0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "id": "mBWWoj0u5Z0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cohere\n"
      ],
      "metadata": {
        "id": "9P00Fz_E44HD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade typing-extensions==4.7"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-3Z8bBk5kgr",
        "outputId": "72eb6c19-0cab-4f6d-c4bb-200706cd57b2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: typing-extensions==4.7 in /usr/local/lib/python3.10/dist-packages (4.7.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade llmx"
      ],
      "metadata": {
        "id": "fRhrzMxv54uW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFo2esOF90E7",
        "outputId": "dfb69304-d450-4f4f-97c4-b0490d33d9f7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: huggingface in /usr/local/lib/python3.10/dist-packages (0.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install langchain huggingface_hub transformers sentence_transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmJrq6NNA3Xk",
        "outputId": "41253555-de22-41a1-82aa-3ffdaf461af7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/86.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/86.0 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for sentence_transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import HuggingFaceHub\n",
        "\n",
        "llm = HuggingFaceHub(repo_id = \"google/flan-t5-xxl\", model_kwargs= {'temperature':0.6})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2rKMEYcj6Dd-",
        "outputId": "6f870813-055a-4772-e5ef-b7229abab2c9"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'InferenceApi' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '1.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n",
            "  warnings.warn(warning_message, FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "name = llm(\"I want to open a restaurant for Indian food. Suggest a fency name for this\")\n",
        "print(name)\n",
        "\n",
        "menu = llm(\"Give me a 5 menu names for Indian restaurant\")\n",
        "print(menu)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLcSrv5L6J74",
        "outputId": "7e73ae5e-1049-402a-b388-a93602f0d4b8"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Indian Fusion\n",
            "tandoori chicken tikka nan sag aloo dhaniya korma saag paneer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "prompt_template_name  = PromptTemplate(\n",
        "    input_variables=['cusine'], template = \"I want to open a restaurant for {cusine} food. Suggest a fency name for this\"\n",
        ")\n",
        "\n",
        "prompt_template_name.format(cusine = 'English')\n",
        "\n",
        "prompt_template_menu = PromptTemplate(\n",
        "    input_variables=['restaurant_name'],\n",
        "    template=\"Suggest 6 menu items for {restaurant_name}. Return it as a comma separated list\"\n",
        ")"
      ],
      "metadata": {
        "id": "Klh1qugMIGJp"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain\n",
        "\n",
        "name_chain = LLMChain(llm = llm, prompt= prompt_template_name)\n",
        "menu_chain = LLMChain(llm = llm, prompt= prompt_template_menu)\n",
        "name_chain.invoke('Indian')\n",
        "menu_chain.invoke('Indian')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pf_xr96FI_F1",
        "outputId": "484edacf-730d-4cdf-cc36-e8973b5edfc0"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'restaurant_name': 'Indian', 'text': ',,,, '}"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import SimpleSequentialChain\n",
        "\n",
        "chain = SimpleSequentialChain(chains=[name_chain, menu_chain])\n",
        "\n",
        "response = chain.invoke(\"Mexican\")\n",
        "print(response)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6uvQuXUKJ9E",
        "outputId": "4085d557-eb49-4668-9dc4-363b36da63ab"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input': 'Mexican', 'output': 'fajitas, enchiladas, burrito, carnitas, chile relleno'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template_name  = PromptTemplate(\n",
        "    input_variables=['cusine'],\n",
        "    template = \"I want to open a restaurant for {cusine} food. Suggest a fency name for this\"\n",
        ")\n",
        "\n",
        "prompt_template_menu = PromptTemplate(\n",
        "    input_variables=['restaurant_name'],\n",
        "    template=\"Suggest 6 menu items for {restaurant_name}. Return it as a comma separated list\"\n",
        ")\n",
        "\n",
        "name_chain = LLMChain(llm = llm, prompt= prompt_template_name,output_key=\"restaurant_name\")\n",
        "menu_chain = LLMChain(llm = llm, prompt= prompt_template_menu, output_key= \"menu_items\")"
      ],
      "metadata": {
        "id": "hunMsH9vNDdv"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import SequentialChain\n",
        "\n",
        "new_chain = SequentialChain(\n",
        "    chains = [name_chain, menu_chain],\n",
        "    input_variables=['cusine'],\n",
        "    output_variables= ['restaurant_name','menu_items']\n",
        ")\n",
        "\n",
        "new_chain({'cusine':'Mexican'})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ymj0l25FN7IX",
        "outputId": "849ff643-cc66-494f-98a0-dc4ef57b5233"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cusine': 'Mexican',\n",
              " 'restaurant_name': 'Mexican food restaurant',\n",
              " 'menu_items': 'fajitas, enchiladas, burrito, carnitas, chile relleno'}"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I753XynbOmtC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}